{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from scipy import signal\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report,accuracy_score,plot_confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropimg(img):\n",
    "    try:\n",
    "        crop = cv2.cvtColor(img,cv2.COLOR_B2GRAY)\n",
    "        height, width = crop.shape\n",
    "        xl=0; xr=width-1; \n",
    "        for i in range(int(width/2)):\n",
    "            if crop[int(height/2),i] <10:\n",
    "                xl = i\n",
    "            if crop[int(height/2),width-1-i] < 10:\n",
    "                xr = width -1- i\n",
    "        test = img[:,xl:xr]\n",
    "    except:\n",
    "        test = img\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractionfeature(path):\n",
    "    img = cv2.imread(path,0)\n",
    "    img = cropimg(img)\n",
    "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    lab_img = cv2.cvtColor(rgb, cv2.COLOR_RGB2LAB)\n",
    "    l,a,b = cv2.split(lab_img)\n",
    "    # create a CLAHE object (Arguments are optional).\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    cll = clahe.apply(l)\n",
    "    update_img = cv2.merge((cll,a,b))\n",
    "    rgb_img = cv2.cvtColor(update_img,cv2.COLOR_LAB2RGB)\n",
    "    final_img = cv2.resize(rgb_img, (112,112), interpolation = cv2.INTER_AREA)\n",
    "    #final_img = cv2.cvtColor(final_img,cv2.COLOR_RGB2GRAY)\n",
    "    fd,hog_img = hog(final_img, orientations=8, pixels_per_cell=(8,8),cells_per_block=(4, 4),block_norm= 'L2',visualize=True,multichannel=True)\n",
    "    return img ,final_img ,fd,hog_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Glaucoma', 'Normal', 'Other']\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "path = r\"C:/Users/Acer/Desktop/projectAI/Train\"\n",
    "os.chdir(path)\n",
    "list_folder = os.listdir()\n",
    "print(list_folder)\n",
    "list_data = [];list_name = [];list_features = [];list_type = []\n",
    "tp = 0\n",
    "count = 0\n",
    "for folder in list_folder:\n",
    "    name_folder = path +\"/\" +folder\n",
    "    os.chdir(name_folder)\n",
    "    list_name_img = os.listdir()\n",
    "    #if(len(list_name_img) > 1500):\n",
    "    list_name_img = list_name_img\n",
    "    for name in list_name_img:\n",
    "        if (count %100 )== 0:\n",
    "            print(count)\n",
    "        path_img = name_folder+\"/\" + name\n",
    "        img ,final_img ,fd,hog_img = extractionfeature(path_img)\n",
    "        #list_data.append([folder+\"_\"+name,tp,fd,img,final_img,hog_img])\n",
    "        list_name.append(folder+\"_\"+name)\n",
    "        list_features.append(fd)\n",
    "        list_type.append(tp)\n",
    "        count +=1\n",
    "    tp +=1\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(list_type).reshape(len(list_type),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(list_features)\n",
    "list_name = [];list_features = [];list_type = []\n",
    "data = np.hstack((labels,features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data[:,0]\n",
    "X = data[:,1:]\n",
    "Y = np.array([np.int32(x) for x in Y])\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfknn = KNeighborsClassifier(n_neighbors = 20)\n",
    "clfknn.fit(x_train, y_train)\n",
    "y_pred = clfknn.predict(x_test)\n",
    "print(\"Accuracy: \"+str(accuracy_score(y_test, y_pred)))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "plot_confusion_matrix(clfknn, x_test, y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "Pkl_Filename = \"modelknn_superwow.pkl\"\n",
    "path = r\"C:/Users/Acer/Desktop/projectAI/muteluh-fundus\"\n",
    "os.chdir(path)\n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(clfknn, file)\n",
    "path = r\"C:/Users/Acer/Desktop/projectAI\"\n",
    "os.chdir(path)\n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(clfknn, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfsvm = svm.SVC(probability=True)\n",
    "clfsvm.fit(x_train,y_train)\n",
    "y_pred = clfsvm.predict(x_test)\n",
    "print(\"Accuracy: \"+str(accuracy_score(y_test, y_pred)))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "plot_confusion_matrix(clfsvm, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "Pkl_Filename = \"modelsvm_superwow5.pkl\"\n",
    "path = r\"C:/Users/Acer/Desktop/projectAI/muteluh-fundus\"\n",
    "os.chdir(path)\n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(clfsvm, file)\n",
    "path = r\"C:/Users/Acer/Desktop/projectAI\"\n",
    "os.chdir(path)\n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(clfsvm, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom(image):\n",
    "    b,g,r = cv2.split(image)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    b = b- b.mean() -b.std()\n",
    "    g = g- g.mean() -g.std()\n",
    "    r = r- r.mean() -r.std()\n",
    "    total = (r+g+b)/3\n",
    "    \n",
    "    #total[total > 2*total.std() ] = 255\n",
    "    b[b < 2.5*b.std()] = 0\n",
    "    b[b > 2.5*b.std()] = 255\n",
    "\n",
    "    gray = gray - gray.mean() -gray.std()\n",
    "    \n",
    "    test = 1.5*total - b - gray\n",
    "    test[test<0] = 0\n",
    "\n",
    "    (minVal, maxVal, minLoc, maxLoc) = cv2.minMaxLoc(test)\n",
    "    height, width, channels = image.shape\n",
    "    rate = height // 5\n",
    "    upper,bottom,left,right = maxLoc[1]-rate,maxLoc[1]+rate,maxLoc[0]-rate,maxLoc[0]+rate\n",
    "    upper = 0 if upper<0 else upper\n",
    "    bottom = 0 if bottom<0 else bottom\n",
    "    left = 0 if left<0 else left\n",
    "    right = 0 if right<0 else right\n",
    "    crop = image[upper:bottom,left:right]\n",
    "    return  cv2.resize(crop, dim, interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
